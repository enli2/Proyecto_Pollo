{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos las clases necesarias para extraer los datos relevabtes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import csv\n",
    "import itertools\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_landmark_list(image, landmarks):\n",
    "    image_width, image_height = image.shape[1], image.shape[0]\n",
    "\n",
    "    landmark_point = []\n",
    "    # Keypoint\n",
    "    for _, landmark in enumerate(landmarks.landmark):\n",
    "        landmark_x = min(int(landmark.x * image_width), image_width - 1)\n",
    "        landmark_y = min(int(landmark.y * image_height), image_height - 1)\n",
    "        # landmark_z = landmark.z\n",
    "\n",
    "        landmark_point.append([landmark_x, landmark_y])\n",
    "\n",
    "    return landmark_point\n",
    "\n",
    "def pre_process_landmark(landmark_list):\n",
    "    temp_landmark_list = copy.deepcopy(landmark_list)\n",
    "\n",
    "    # Convert to relative coordinates\n",
    "    base_x, base_y = 0, 0\n",
    "    for index, landmark_point in enumerate(temp_landmark_list):\n",
    "        if index == 0:\n",
    "            base_x, base_y = landmark_point[0], landmark_point[1]\n",
    "\n",
    "        temp_landmark_list[index][0] = temp_landmark_list[index][0] - base_x\n",
    "        temp_landmark_list[index][1] = temp_landmark_list[index][1] - base_y\n",
    "\n",
    "    # Convert to a one-dimensional list\n",
    "    temp_landmark_list = list(\n",
    "        itertools.chain.from_iterable(temp_landmark_list))\n",
    "\n",
    "    # Normalization\n",
    "    max_value = max(list(map(abs, temp_landmark_list)))\n",
    "\n",
    "    def normalize_(n):\n",
    "        return n / max_value\n",
    "\n",
    "    temp_landmark_list = list(map(normalize_, temp_landmark_list))\n",
    "\n",
    "    return temp_landmark_list\n",
    "\n",
    "\n",
    "def logging_csv(number, mode, landmark_list,csv_path):\n",
    "    if mode == 0:\n",
    "        pass\n",
    "    if mode == 1 and (0 <= number <= 9):\n",
    "        with open(csv_path, 'a', newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([number, *landmark_list])\n",
    "    return\n",
    "\n",
    "\n",
    "def extract_feature(dirt,number_gest):\n",
    "    csv_path = 'model/keypoint_classifier/keypoint.csv'\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    mp_drawing_styles = mp.solutions.drawing_styles\n",
    "    mp_hands = mp.solutions.hands\n",
    "    with os.scandir(dirt) as ficheros:\n",
    "        ficheros = [dirt+\"\\\\\"+fichero.name for fichero in ficheros if fichero.is_file()and fichero.name.endswith('.png')]\n",
    "    # For static images:\n",
    "    IMAGE_FILES = ficheros\n",
    "\n",
    "    hands = mp_hands.Hands(\n",
    "            static_image_mode='store_true',\n",
    "            max_num_hands=1,\n",
    "            min_detection_confidence=0.7,\n",
    "            min_tracking_confidence=0.5,\n",
    "        )\n",
    "    for idx, file in enumerate(IMAGE_FILES):\n",
    "        # Read an image, flip it around y-axis for correct handedness output (see\n",
    "        # above).\n",
    "        image = cv2.imread(file)    \n",
    "        # Convert the BGR image to RGB before processing.\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(image)\n",
    "        if results.multi_hand_landmarks is not None:\n",
    "            for hand_landmarks, handedness in zip(results.multi_hand_landmarks,\n",
    "                                                    results.multi_handedness):\n",
    "                landmark_list = calc_landmark_list(image, hand_landmarks)\n",
    "                    # Conversion to relative coordinates / normalized coordinates\n",
    "                pre_processed_landmark_list = pre_process_landmark(landmark_list)\n",
    "        \n",
    "                logging_csv(number_gest, 1, pre_processed_landmark_list,csv_path)\n",
    "                # mp_drawing.draw_landmarks(\n",
    "                #         image,\n",
    "                #         hand_landmarks,\n",
    "                #         mp_hands.HAND_CONNECTIONS,\n",
    "                #         mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                #         mp_drawing_styles.get_default_hand_connections_style()\n",
    "                #         )\n",
    "                # plt.imshow(image.squeeze())\n",
    "                # plt.axis(\"off\")\n",
    "                # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class_group=[ \"jump\",\"right\",\"left\",\"fit\",\"reset\",\"back\"]\n",
    "dirt=\"dataset\\\\train\\\\\"\n",
    "label_path=\"model/keypoint_classifier/keypoint_classifier_label.csv\"\n",
    "\n",
    "for id_class,label in enumerate(class_group):\n",
    "    extract_feature(dirt+label,id_class)\n",
    "    with open(label_path, 'a', newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([label])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e66769476dfa4fadb19cb01be873cefad5ddda11f815c0af291852f7b6041665"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
